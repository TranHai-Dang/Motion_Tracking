import streamlit as st
import mediapipe as mp
import cv2
import numpy as np
import av
import time
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase, RTCConfiguration, WebRtcMode

# --- 1. IMPORT C√ÅC B√ÄI T·∫¨P ---
try:
    from WarmUp.jumpingjack import JumpingJackExercise
    from WarmUp.sidebend import SideBendExercise
    from Exercise.squat import SquatExercise
    from Exercise.pushup import PushUpExercise
    from Challenge.plank import PlankExercise
    from Challenge.highknees import HighKneesExercise
except ImportError as e:
    st.error(f"‚ùå L·ªói Import: {e}. H√£y ki·ªÉm tra l·∫°i c·∫•u tr√∫c th∆∞ m·ª•c.")
    st.stop()

# --- 2. D·ªÆ LI·ªÜU H∆Ø·ªöNG D·∫™N ---
GUIDE_VIETNAMESE = {
    "Jumping Jack": "1. ƒê·ª©ng th·∫≥ng, hai ch√¢n kh√©p, tay xu√¥i theo th√¢n.\n\n2. B·∫≠t nh·∫£y, dang hai ch√¢n r·ªông h∆°n vai, vung tay l√™n cao ƒë·∫≠p v√†o nhau.\n\n3. B·∫≠t nh·∫£y tr·ªü v·ªÅ t∆∞ th·∫ø ban ƒë·∫ßu.\n\nüëâ *M·∫πo: Gi·ªØ nh·ªãp th·ªü ƒë·ªÅu, ti·∫øp ƒë·∫•t b·∫±ng m≈©i ch√¢n.*",
    "Side Bend": "1. ƒê·ª©ng th·∫≥ng, hai ch√¢n r·ªông b·∫±ng vai.\n\n2. Nghi√™ng l∆∞·ªùn sang tr√°i s√¢u h·∫øt m·ª©c c√≥ th·ªÉ.\n\n3. Tr·ªü v·ªÅ gi·ªØa r·ªìi nghi√™ng sang ph·∫£i.\n\nüëâ *M·∫πo: Kh√¥ng c√∫i ng∆∞·ªùi v·ªÅ tr∆∞·ªõc, ch·ªâ nghi√™ng sang ngang.*",
    "Squat": "1. ƒê·ª©ng th·∫≥ng, ch√¢n r·ªông b·∫±ng vai.\n\n2. H·∫° h√¥ng xu·ªëng nh∆∞ ƒëang ng·ªìi tr√™n gh·∫ø (ƒë√πi song song s√†n).\n\n3. ƒê·ª©ng th·∫≥ng d·∫≠y.\n\nüëâ *M·∫πo: Gi·ªØ l∆∞ng th·∫≥ng, ƒë·∫ßu g·ªëi kh√¥ng v∆∞·ª£t qu√° m≈©i ch√¢n.*",
    "Push Up": "1. Ch·ªëng tay xu·ªëng s√†n, th√¢n ng∆∞·ªùi th·∫≥ng.\n\n2. H·∫° ng·ª±c xu·ªëng g·∫ßn ch·∫°m s√†n.\n\n3. ƒê·∫©y ng∆∞·ªùi l√™n th·∫≥ng tay.\n\nüëâ *M·∫πo: G·ªìng b·ª•ng, kh√¥ng ƒë·ªÉ v√µng l∆∞ng.*",
    "Plank": "1. Ch·ªëng khu·ª∑u tay xu·ªëng s√†n.\n\n2. Gi·ªØ ng∆∞·ªùi th·∫≥ng t·∫Øp, g·ªìng ch·∫∑t b·ª•ng.\n\n3. Gi·ªØ nguy√™n t∆∞ th·∫ø c√†ng l√¢u c√†ng t·ªët.\n\nüëâ *M·∫πo: ƒê·ª´ng ƒë·∫©y m√¥ng qu√° cao ho·∫∑c ƒë·ªÉ l∆∞ng b·ªã v√µng.*",
    "High Knees": "1. Ch·∫°y t·∫°i ch·ªó.\n\n2. N√¢ng ƒë√πi cao vu√¥ng g√≥c v·ªõi th√¢n ng∆∞·ªùi.\n\n3. ƒê√°nh tay m·∫°nh theo nh·ªãp.\n\nüëâ *M·∫πo: C·ªë g·∫Øng n√¢ng ƒë√πi c√†ng cao c√†ng t·ªët.*"
}

# --- 3. CLASS X·ª¨ L√ù AI (N√¢ng c·∫•p: C√≥ tr√≠ nh·ªõ) ---
class PoseProcessor(VideoProcessorBase):
    def __init__(self):
        self.mp_pose = mp.solutions.pose
        self.pose = self.mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)
        self.mp_drawing = mp.solutions.drawing_utils
        self.exercise = None 
        self.flip = True  
        self.rotate_type = "Kh√¥ng xoay"
        
        # --- BI·∫æN L∆ØU TR·ªÆ L·ªäCH S·ª¨ T·∫¨P ---
        self.total_reps = 0
        self.error_log = [] # L∆∞u danh s√°ch l·ªói (VD: ["L∆∞ng cong", "Ch∆∞a xu·ªëng s√¢u"])

    def set_exercise(self, exercise_class):
        if exercise_class:
            self.exercise = exercise_class()
            self.exercise.reset()
            # Reset l·ªãch s·ª≠ khi ƒë·ªïi b√†i
            self.total_reps = 0
            self.error_log = []

    def recv(self, frame: av.VideoFrame) -> av.VideoFrame:
        try:
            img = frame.to_ndarray(format="bgr24")

            # 1. X·ª≠ l√Ω xoay/l·∫≠t
            if self.flip:
                img = cv2.flip(img, 1)
            
            if self.rotate_type == "Xoay tr√°i 90¬∞":
                img = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)
            elif self.rotate_type == "Xoay ph·∫£i 90¬∞":
                img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)
            elif self.rotate_type == "Xoay 180¬∞":
                img = cv2.rotate(img, cv2.ROTATE_180)

            # 2. X·ª≠ l√Ω AI
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            results = self.pose.process(img_rgb)
            
            status_color = (0, 165, 255) # Cam
            info_text = "AI Ready..."

            if results.pose_landmarks:
                self.mp_drawing.draw_landmarks(img, results.pose_landmarks, self.mp_pose.POSE_CONNECTIONS)
                
                if self.exercise:
                    try:
                        angle, count, feedback, stage = self.exercise.process(results.pose_landmarks.landmark)
                        
                        # C·∫≠p nh·∫≠t Reps
                        self.total_reps = count
                        
                        # Ghi nh·ªõ l·ªói (N·∫øu feedback kh√¥ng ph·∫£i "Good" v√† ch∆∞a c√≥ trong log g·∫ßn nh·∫•t)
                        if feedback and "Good" not in feedback and "Tot" not in feedback and "Start" not in feedback:
                             # Ch·ªâ l∆∞u l·ªói n·∫øu n√≥ kh√¥ng b·ªã tr√πng l·∫∑p li√™n t·ª•c (tr√°nh spam)
                            if not self.error_log or self.error_log[-1] != feedback:
                                self.error_log.append(feedback)

                        info_text = f"Rep: {count} | {feedback}"
                        if "Good" in feedback or "Tot" in feedback: 
                            status_color = (0, 255, 0)
                        elif "FIX" in feedback or "Ha" in feedback: 
                            status_color = (0, 0, 255)
                    except:
                        pass
            
            # 3. V·∫Ω th√¥ng b√°o
            cv2.rectangle(img, (0,0), (img.shape[1], 60), (50, 50, 50), -1)
            cv2.putText(img, info_text, (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, status_color, 2, cv2.LINE_AA)

            return av.VideoFrame.from_ndarray(img, format="bgr24")
        
        except Exception as e:
            print(e)
            return frame

# --- 4. GIAO DI·ªÜN CH√çNH ---
def main():
    st.set_page_config(page_title="Virtual Rehab AI", layout="wide")
    
    # CSS Full m√†n h√¨nh
    st.markdown(
        """
        <style>
        .block-container { padding-top: 1rem; padding-bottom: 1rem; }
        video { width: 100% !important; height: auto !important; border-radius: 10px; }
        div[class*="stWebrtc"] { width: 100% !important; }
        div[class*="stWebrtc"] > div { width: 100% !important; }
        </style>
        """,
        unsafe_allow_html=True
    )

    # --- SIDEBAR ---
    with st.sidebar:
        st.title("üéõÔ∏è B·∫£ng ƒêi·ªÅu Khi·ªÉn")
        
        CLASS_MAP = {
            "Jumping Jack": JumpingJackExercise,
            "Side Bend": SideBendExercise,
            "Squat": SquatExercise,
            "Push Up": PushUpExercise,
            "Plank": PlankExercise,
            "High Knees": HighKneesExercise
        }
        
        MENU = {
            "Kh·ªüi ƒë·ªông": ["Jumping Jack", "Side Bend"],
            "T·∫≠p luy·ªán": ["Squat", "Push Up"],
            "Th·ª≠ th√°ch": ["Plank", "High Knees"]
        }

        st.subheader("1. Ch·ªçn B√†i T·∫≠p")
        mode = st.selectbox("Ch·∫ø ƒë·ªô:", list(MENU.keys()))
        exercise_name = st.selectbox("B√†i t·∫≠p:", MENU[mode])
        current_exercise = CLASS_MAP[exercise_name]

        st.markdown("---")
        st.subheader("üìñ H∆∞·ªõng D·∫´n")
        st.info(GUIDE_VIETNAMESE.get(exercise_name, ""))

        st.markdown("---")
        st.subheader("üì∑ C√†i ƒë·∫∑t Camera")
        flip = st.checkbox("L·∫≠t g∆∞∆°ng", value=True)
        rotate = st.radio("Xoay:", ("Kh√¥ng xoay", "Xoay tr√°i 90¬∞", "Xoay ph·∫£i 90¬∞"))

    # --- M√ÄN H√åNH CH√çNH ---
    st.title(f"üèãÔ∏è {exercise_name}")
    
    rtc_config = RTCConfiguration({"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]})

    # C·∫•u h√¨nh ƒë·ªÉ l∆∞u video
    # media_stream_recorder=True gi√∫p hi·ªán n√∫t "Record" tr√™n video
    ctx = webrtc_streamer(
        key="rehab-cam",
        video_processor_factory=PoseProcessor,
        mode=WebRtcMode.SENDRECV,
        rtc_configuration=rtc_config,
        media_stream_constraints={"video": True, "audio": False},
        async_processing=False
    )

    # X·ª≠ l√Ω th√¥ng s·ªë g·ª≠i v√†o AI
    if ctx.video_processor:
        ctx.video_processor.set_exercise(current_exercise)
        ctx.video_processor.flip = flip
        ctx.video_processor.rotate_type = rotate

    # --- PH·∫¶N B√ÅO C√ÅO K·∫æT QU·∫¢ (REPORT) ---
    # Khi ng∆∞·ªùi d√πng t·∫Øt camera ho·∫∑c d·ª´ng t·∫≠p, hi·ªÉn th·ªã k·∫øt qu·∫£
    if not ctx.state.playing and ctx.video_processor:
        processor = ctx.video_processor
        if processor.total_reps > 0 or len(processor.error_log) > 0:
            st.divider()
            st.subheader("üìä B√°o C√°o Bu·ªïi T·∫≠p")
            
            col_rep, col_score = st.columns(2)
            
            # 1. S·ªë Reps
            with col_rep:
                st.metric(label="T·ªïng s·ªë l·∫ßn t·∫≠p (Reps)", value=processor.total_reps)
            
            # 2. Ch·∫•m ƒëi·ªÉm (Gi·∫£ l·∫≠p: C√†ng √≠t l·ªói ƒëi·ªÉm c√†ng cao)
            with col_score:
                error_count = len(processor.error_log)
                score = max(0, 100 - (error_count * 5)) # M·ªói l·ªói tr·ª´ 5 ƒëi·ªÉm
                
                if score >= 80:
                    grade = "Xu·∫•t s·∫Øc üèÜ"
                    color = "green"
                elif score >= 50:
                    grade = "Kh√° üëç"
                    color = "orange"
                else:
                    grade = "C·∫ßn c·ªë g·∫Øng ‚ö†Ô∏è"
                    color = "red"
                    
                st.metric(label="ƒêi·ªÉm T∆∞ Th·∫ø", value=f"{score}/100", delta=grade)

            # 3. Ph√¢n t√≠ch l·ªói
            if processor.error_log:
                st.warning("üßê C√°c v·∫•n ƒë·ªÅ c·∫ßn c·∫£i thi·ªán:")
                # ƒê·∫øm s·ªë l·∫ßn xu·∫•t hi·ªán c·ªßa t·ª´ng l·ªói
                from collections import Counter
                error_counts = Counter(processor.error_log)
                
                for err, count in error_counts.items():
                    st.write(f"- **{err}**: L·∫∑p l·∫°i {count} l·∫ßn")
            else:
                st.success("üéâ Tuy·ªát v·ªùi! B·∫°n kh√¥ng m·∫Øc l·ªói n√†o.")

if __name__ == "__main__":
    main()